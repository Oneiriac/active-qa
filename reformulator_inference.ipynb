{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from px.nmt import reformulator\n",
    "from px.proto import reformulator_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Num encoder layer 2 is different from num decoder layer 4, so set pass_hidden_state to False\n",
      "# hparams:\n",
      "  src=source\n",
      "  tgt=target\n",
      "  train_prefix=None\n",
      "  dev_prefix=None\n",
      "  test_prefix=None\n",
      "  train_annotations=None\n",
      "  dev_annotations=None\n",
      "  test_annotations=None\n",
      "  out_dir=/tmp/active-qa/reformulator\n",
      "# Vocab file data/spm2/spm.unigram.16k.vocab.nocount.notab.source exists\n",
      "  using source vocab for target\n",
      "INFO:tensorflow:loading vocab for trie\n",
      "# Use the same embedding for source and target\n",
      "# creating train graph ...\n",
      "  num_bi_layers = 1\n",
      "  num_uni_layers = 1\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "WARNING:tensorflow:From /Users/dcai0006/PycharmProjects/active-qa/px/nmt/model_helper.py:611: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  decoding maximum_iterations 50\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 1",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 2",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 3",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  learning_rate=0.01, warmup_steps=0, warmup_scheme=t2t\n",
      "  decay_scheme=luong10, start_decay_step=5000000, decay_steps 500000, decay_factor 0.5\n",
      "# Trainable variables\n",
      "  embeddings/embedding_share/part_0:0, (8000, 512), /device:GPU:0\n",
      "  embeddings/embedding_share/part_1:0, (8000, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/query_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_v:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_g:0, (), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_b:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 16000), \n",
      "# Use the same embedding for source and target",
      "\n",
      "# creating infer graph ...\n",
      "  num_bi_layers = 1\n",
      "  num_uni_layers = 1\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  decoding maximum_iterations 50\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 1",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 2",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 3",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "# Trainable variables\n",
      "  embeddings/embedding_share/part_0:0, (8000, 512), /device:GPU:0\n",
      "  embeddings/embedding_share/part_1:0, (8000, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/query_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_v:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_g:0, (), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_b:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 16000), \n",
      "# Use the same embedding for source and target\n",
      "# creating infer graph ...\n",
      "  num_bi_layers = 1\n",
      "  num_uni_layers = 1\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  decoding maximum_iterations 50\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 1",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 2",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 3",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "# Trainable variables\n",
      "  embeddings/embedding_share/part_0:0, (8000, 512), /device:GPU:0\n",
      "  embeddings/embedding_share/part_1:0, (8000, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/query_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_v:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_g:0, (), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_b:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 16000), \n",
      "# Use the same embedding for source and target\n",
      "# creating infer graph ...\n",
      "  num_bi_layers = 1\n",
      "  num_uni_layers = 1\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  decoding maximum_iterations 50\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 1",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 2",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 3",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "# Trainable variables\n",
      "  embeddings/embedding_share/part_0:0, (8000, 512), /device:GPU:0\n",
      "  embeddings/embedding_share/part_1:0, (8000, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/query_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_v:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_g:0, (), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_b:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 16000), \n",
      "# Use the same embedding for source and target\n",
      "# creating infer graph ...\n",
      "  num_bi_layers = 1\n",
      "  num_uni_layers = 1\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  decoding maximum_iterations 50\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 1",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 2",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 3",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "# Trainable variables\n",
      "  embeddings/embedding_share/part_0:0, (8000, 512), /device:GPU:0\n",
      "  embeddings/embedding_share/part_1:0, (8000, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/query_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_v:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_g:0, (), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_b:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 16000), \n",
      "# Use the same embedding for source and target\n",
      "# creating infer graph ...\n",
      "  num_bi_layers = 1\n",
      "  num_uni_layers = 1\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  decoding maximum_iterations 50\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 1",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 2",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 3",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "# Trainable variables\n",
      "  embeddings/embedding_share/part_0:0, (8000, 512), /device:GPU:0\n",
      "  embeddings/embedding_share/part_1:0, (8000, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/query_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_v:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_g:0, (), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_b:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 16000), \n",
      "# Use the same embedding for source and target\n",
      "# creating infer graph ...\n",
      "  num_bi_layers = 1\n",
      "  num_uni_layers = 1\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  decoding maximum_iterations 50\n",
      "  cell 0",
      "  LSTM, forget_bias=1",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 1",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 2",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "  cell 3",
      "  LSTM, forget_bias=1",
      "  ResidualWrapper",
      "  DeviceWrapper, device=/gpu:0",
      "\n",
      "# Trainable variables\n",
      "  embeddings/embedding_share/part_0:0, (8000, 512), /device:GPU:0\n",
      "  embeddings/embedding_share/part_1:0, (8000, 512), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel:0, (1024, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/memory_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/query_layer/kernel:0, (512, 512), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_v:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_g:0, (), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_b:0, (512,), \n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/kernel:0, (1536, 2048), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/bias:0, (2048,), /device:GPU:0\n",
      "  dynamic_seq2seq/decoder/output_projection/kernel:0, (512, 16000), \n",
      "INFO:tensorflow:Restoring parameters from /Users/dcai0006/data/pretrained/translate.ckpt-1460356\n",
      "INFO:tensorflow:adding variable Variable to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/memory_layer/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_b to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_g to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/attention_v to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/bahdanau_attention/query_layer/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/output_projection/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/bias to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_0_attention/attention/basic_lstm_cell/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/bias to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_1/basic_lstm_cell/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/bias to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_2/basic_lstm_cell/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/bias to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/decoder/multi_rnn_cell/cell_3/basic_lstm_cell/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/bias to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/encoder/bidirectional_rnn/bw/basic_lstm_cell/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/bias to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/encoder/bidirectional_rnn/fw/basic_lstm_cell/kernel to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/encoder/rnn/basic_lstm_cell/bias to be restored\n",
      "INFO:tensorflow:adding variable dynamic_seq2seq/encoder/rnn/basic_lstm_cell/kernel to be restored\n",
      "INFO:tensorflow:variable embeddings/embedding_share/part_0 is sharded\n",
      "INFO:tensorflow:adding variable embeddings/embedding_share to be restored\n",
      "INFO:tensorflow:variable embeddings/embedding_share/part_1 is sharded\n",
      "INFO:tensorflow:adding variable embeddings/embedding_share to be restored\n",
      "INFO:tensorflow:Initializing uninitialized variables.\n",
      "  loaded train model parameters from /Users/dcai0006/data/pretrained/translate.ckpt-1460356, time 0.92s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "reformulator_instance = reformulator.Reformulator(\n",
    "    hparams_path='px/nmt/example_configs/reformulator.json',\n",
    "    source_prefix='<en> <2en> ',\n",
    "    out_dir='/tmp/active-qa/reformulator',\n",
    "    environment_server_address='localhost:10000')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'Where is my faculty and how do I get course advice?',\n",
    "    'Can students buy red parking permits?',\n",
    "    'How can I lodge a complaint about a faculty member?'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Where do you get career advice?\nWhere is my faculty and how do you get a course?\nWhere is my faculty and how do you get orientation?\nWhere is my faculty and how do you get career advice?\nWhere is my faculty and how do you get course advice?\nWhere do you get a course on my faculty?\nWhere is my faculty and how do you get a course advisor?\nWhere is my faculty and how do you get a course advice?\nWhere is my faculty and how do you get counsel?\nWhere do you get a course advice?\nWhere do you get course advice?\nWhere is my faculty and how do you get coach?\nWhere do you get a course advisor?\nWhere is my faculty?\nWhere is my faculty and how do you get training?\nWhere is my faculty and how do you get a course of advice?\nWhere is my faculty and how do you get course?\nWhere is my faculty and how do you get a course of counsel?\nWhere is my faculty and how do you get it's career advice?\nWhere is my faculty and how do you get it's career?\n====================\nCan you buy red parking permits?\nCan you buy red parking licenses?\nCan students buy red parking permits?\nCan you buy parking permits?\nCan pupil buy red parking permits?\nCan you buy a red parking permits?\nCan a student buy red parking permits?\nCan you buy red parking?\nCan student buy red parking permits?\nCan you buy a red parking permit?\nCan students buy red parking licenses?\nCan you buy a red parking license?\nCan students buy red parking?\nCan you buy red parking authors?\nCan you buy parking licenses?\nCan students buy parking permits?\nCan a student buy red parking?\nCan you buy red parking license?\nCan you buy a red parking?\nCan you buy red parking's permits?\n====================\nHow can you file a complaint about a faculty member?\nHow can you lodge a complaint about a faculty member?\nHow can you file a complaint about a professor?\nHow do you file a complaint about a faculty member?\nHow can you lodge a complaint about a professor?\nHow do you lodge a complaint about a faculty member?\nHow can you file a complaint about an faculty member?\nHow can you file a complaint about a professor member?\nHow can you file a complaint about a profession member?\nHow can you file a complaint about a female faculty member?\nHow can you lodge a complaint about a profession member?\nHow can you file a complaint about a teacher?\nHow can you lodge a complaint about a professor member?\nHow can you lodge a complaint about a teacher?\nHow can you lodge a complaint about a female faculty member?\nHow do you file a complaint about a professor?\nHow do you lodge a complaint about a professor?\nHow can you file a complaint about a teacher member?\nHow can you file a complaint about a professional member?\nHow can you lodge a complaint about a professional member?\n====================\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Change from GREEDY to BEAM_SEARCH if you want 20 rewrites instead of one.\n",
    "inference_mode = reformulator_pb2.ReformulatorRequest.BEAM_SEARCH\n",
    "responses = reformulator_instance.reformulate(\n",
    "    questions=questions,\n",
    "    inference_mode=inference_mode)\n",
    "\n",
    "if inference_mode == reformulator_pb2.ReformulatorRequest.GREEDY:\n",
    "    # Since we are using greedy decoder, keep only the first rewrite.\n",
    "    reformulations = [r[0].reformulation for r in responses]\n",
    "else:\n",
    "    reformulations = [[t.reformulation for t in r] for r in responses]\n",
    "\n",
    "for r in reformulations:\n",
    "    for t in r:\n",
    "        print(t)\n",
    "    print('='*20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}